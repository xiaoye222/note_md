## http

### 请求方法

| 序号 | 方法    | 描述                                                         |
| :--- | :------ | :----------------------------------------------------------- |
| 1    | GET     | 请求指定的页面信息，并返回实体主体。                         |
| 2    | HEAD    | 类似于 GET 请求，只不过返回的响应中没有具体的内容，用于获取报头 |
| 3    | POST    | 不是幂等的方法，向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST 请求可能会导致新的资源的建立和/或已有资源的修改。用于提交请求，可以更新或者创建资源，是非幂等的。 |
| 4    | PUT     | 幂等的方法，从客户端向服务器传送的数据取代指定的文档的内容。用于向指定的url传送更新资源。  更新整个资源。 |
| 5    | DELETE  | 请求服务器删除指定的页面。                                   |
| 6    | CONNECT | HTTP/1.1 协议中预留给能够将连接改为管道方式的代理服务器。    |
| 7    | OPTIONS | 允许客户端查看服务器的性能。                                 |
| 8    | TRACE   | 回显服务器收到的请求，主要用于测试或诊断。                   |
| 9    | PATCH   | 是对 PUT 方法的补充，用来对已知资源进行局部更新。 非幂等，更新部分资源。 |

幂等：数学中的一个术语，对于单个输入或者无输入的运算方法，如果每次都是同样的结果，则是幂等的。也就是说，如果一个网络重复执行多次，产生的效果是一样的，那就是幂等。

如果该更新对应的url多次调用的结果一致，用put

如果每次提交相同的内容，最终结果不一致，用post



**patch与put的应用场景**

一个计量单位实体`MeasurementUnit`，有`name`，`weight`，`measurementUnitCategory`等多个字段，在这里，只修改`weight`这个字段，该如何选择？

为省事，直接将修改了`weight`的完整的`MeasurementUnit`对象直接传给后台。但是这种做法实际上并不明智，这会浪费大量的网络带宽。

但是`patch`呢，他会只将`weight`传到制定资源去，表示这是一个局部更新，后端只更新收到的字段。





1、学习整理http、aixos、vue.config.js配置相关知识点

2、学习整理数据类型、数组、对象、字符串常用方法

3、学习vue3.x 组合式api概念



### 响应的状态码

```
1xx:信息
 
100 Continue
服务器仅接收到部分请求，但是一旦服务器并没有拒绝该请求，客户端应该继续发送其余的请求。
101 Switching Protocols
服务器转换协议：服务器将遵从客户的请求转换到另外一种协议。
 
 
 
2xx:成功
 
200 OK
请求成功（其后是对GET和POST请求的应答文档）
201 Created
请求被创建完成，同时新的资源被创建。
202 Accepted
供处理的请求已被接受，但是处理未完成。
203 Non-authoritative Information
文档已经正常地返回，但一些应答头可能不正确，因为使用的是文档的拷贝。
204 No Content
没有新文档。浏览器应该继续显示原来的文档。如果用户定期地刷新页面，而Servlet可以确定用户文档足够新，这个状态代码是很有用的。
205 Reset Content
没有新文档。但浏览器应该重置它所显示的内容。用来强制浏览器清除表单输入内容。
206 Partial Content
客户发送了一个带有Range头的GET请求，服务器完成了它。
 
 
 
3xx:重定向
 
300 Multiple Choices
多重选择。链接列表。用户可以选择某链接到达目的地。最多允许五个地址。
301 Moved Permanently
所请求的页面已经转移至新的url。
302 Moved Temporarily
所请求的页面已经临时转移至新的url。
303 See Other
所请求的页面可在别的url下被找到。
304 Not Modified
未按预期修改文档。客户端有缓冲的文档并发出了一个条件性的请求（一般是提供If-Modified-Since头表示客户只想比指定日期更新的文档）。服务器告诉客户，原来缓冲的文档还可以继续使用。
305 Use Proxy
客户请求的文档应该通过Location头所指明的代理服务器提取。
306 Unused
此代码被用于前一版本。目前已不再使用，但是代码依然被保留。
307 Temporary Redirect
被请求的页面已经临时移至新的url。
 
 
 
4xx:客户端错误
 
400 Bad Request
服务器未能理解请求。
401 Unauthorized
被请求的页面需要用户名和密码。
401.1
登录失败。
401.2
服务器配置导致登录失败。
401.3
由于 ACL 对资源的限制而未获得授权。
401.4
筛选器授权失败。
401.5
ISAPI/CGI 应用程序授权失败。
401.7
访问被 Web 服务器上的 URL 授权策略拒绝。这个错误代码为 IIS 6.0 所专用。
402 Payment Required
此代码尚无法使用。
403 Forbidden
对被请求页面的访问被禁止。
403.1
执行访问被禁止。
403.2
读访问被禁止。
403.3
写访问被禁止。
403.4
要求 SSL。
403.5
要求 SSL 128。
403.6
IP 地址被拒绝。
403.7
要求客户端证书。
403.8
站点访问被拒绝。
403.9
用户数过多。
403.10
配置无效。
403.11
密码更改。
403.12
拒绝访问映射表。
403.13
客户端证书被吊销。
403.14
拒绝目录列表。
403.15
超出客户端访问许可。
403.16
客户端证书不受信任或无效。
403.17
客户端证书已过期或尚未生效。
403.18
在当前的应用程序池中不能执行所请求的 URL。这个错误代码为 IIS 6.0 所专用。
403.19
不能为这个应用程序池中的客户端执行 CGI。这个错误代码为 IIS 6.0 所专用。
403.20
Passport 登录失败。这个错误代码为 IIS 6.0 所专用。
404 Not Found
服务器无法找到被请求的页面。
404.0
没有找到文件或目录。
404.1
无法在所请求的端口上访问 Web 站点。
404.2
Web 服务扩展锁定策略阻止本请求。
404.3
MIME 映射策略阻止本请求。
405 Method Not Allowed
请求中指定的方法不被允许。
406 Not Acceptable
服务器生成的响应无法被客户端所接受。
407 Proxy Authentication Required
用户必须首先使用代理服务器进行验证，这样请求才会被处理。
408 Request Timeout
请求超出了服务器的等待时间。
409 Conflict
由于冲突，请求无法被完成。
410 Gone
被请求的页面不可用。
411 Length Required
"Content-Length" 未被定义。如果无此内容，服务器不会接受请求。
412 Precondition Failed
请求中的前提条件被服务器评估为失败。
413 Request Entity Too Large
由于所请求的实体的太大，服务器不会接受请求。
414 Request-url Too Long
由于url太长，服务器不会接受请求。当post请求被转换为带有很长的查询信息的get请求时，就会发生这种情况。
415 Unsupported Media Type
由于媒介类型不被支持，服务器不会接受请求。
416 Requested Range Not Satisfiable
服务器不能满足客户在请求中指定的Range头。
417 Expectation Failed
执行失败。
423
锁定的错误。
 
 
 
5xx:服务器错误
 
500 Internal Server Error
请求未完成。服务器遇到不可预知的情况。
500.12
应用程序正忙于在 Web 服务器上重新启动。
500.13
Web 服务器太忙。
500.15
不允许直接请求 Global.asa。
500.16
UNC 授权凭据不正确。这个错误代码为 IIS 6.0 所专用。
500.18
URL 授权存储不能打开。这个错误代码为 IIS 6.0 所专用。
500.100
内部 ASP 错误。
501 Not Implemented
请求未完成。服务器不支持所请求的功能。
502 Bad Gateway
请求未完成。服务器从上游服务器收到一个无效的响应。
502.1
CGI 应用程序超时。　·
502.2
CGI 应用程序出错。
503 Service Unavailable
请求未完成。服务器临时过载或当机。
504 Gateway Timeout
网关超时。
505 HTTP Version Not Supported
服务器不支持请求中指明的HTTP协议版本
```

### [握手挥手](https://juejin.cn/post/6844903829880700941) 

#### 解释 

- **同步 SYN** ：synchronous。建立连接，将 SYN = 1。
- **序号 seq**: sequence。第一个字节的编号随机产生。
- **确认位 ACK** ： acknowledgement 。
- **ack** : 表示确认字段的值。（对哪个进行确认）。
- **结束 FIN** ： finish。FIN = 1 表示希望断开连接。

#### 状态 

- **SYN-SENT** : 同步已发送。
- **SYN-RCVD**：同步收到。
- **ESTABLISHED**: 已建立连接。
- **FIN-WAIT-1**：终止等待1。
- **FIN-WAIT-2**：终止等待2。
- **CLOSE-WAIT**： 关闭等待。 
- **LAST-ACK** : 最后确认。
- **TIME-WAIT**: 时间等待。 
- **CLOSED** ：关闭状态。

#### 三次握手

TCP建立连接的过程叫做握手，握手需要在客户和服务器之间交换三个 TCP 报文段。

![](C:\Users\刘颖\Pictures\笔记\三次握手.jpg)

最初，客户端和服务器的 TCP 进程都处于 **CLOSED (关闭)** 状态。B 的 TCP 服务器进程先创建 **传输控制块 TCB** ，准备接受客户进程的连接请求。然后服务器进程处于 **LISTEN (收听)** 状态，等待客户的连接请求。A 的 TCP 客户进程也是首先创建 **传输控制块 TCB** 。

**第一次握手** ： 客户端打算建立连接时，向服务器发出连接请求报文段，此时首部中的同步位 SYN = 1 ，同时选择一个初始需要 seq = x 。 TCP 规定，SYN = 1 的报文段 不能携带数据，但要消耗掉一个序号。这时，TCP 客户进程进入 **SYN-SENT （同步已发送）**状态。

**第二次握手**：服务器收到连接请求报文段后，如果同意建立连接，则向客户端发送确认。在确认报文段中应把 SYN 位 和 ACK 位 都置 1 ，确认号是 ack = x + 1，同时也为自己选择一个初始序号 seq = y。（这个报文段也不能携带数据，但同样要消耗掉一个序号。）这时 TCP 服务器进程进入 **SYN-RCVD (同步收到)** 状态。

**第三次握手**：客户端收到服务器的确认后，还要向服务器给出确认。确认报文段的 ACK 置为 1 ，确认号 ack = y + 1，而自己的序号 seq = x + 1 。这时， TCP 连接已经建立，客户端进入 **ESTABLISHED (已建立连接)** 状态。当 服务器 收到 客户端 的确认后，也进入 **ESTABLISHED (已建立连接)** 状态。

通过这样的三次握手，客户端与服务器端建立可靠的双工的连接，开始传送数据。三次握手的主要目的是保证连接是双工的，可靠更多是通过重传机制来保证的。

##### 为什么 客户端 最后还要发送一次确认？

主要是为了**防止已失效的连接请求报文段突然又传到了 服务器，因而产生错误**。 

现假定出现一种异常情况，即客户端发出的第一个连接请求报文段并没有丢失，而是在某些网络结点长时间滞留了，以致延误到连接释放以后的某个时间才到达服务器。本来这是一个早已失效的报文段。但 服务器收到此失效的连接请求报文段后，就误认为是客户端又发出一次新的连接请求。于是就向客户端 发出确认报文段，同意建立连接。假定不采用报文握手，那么只要服务器发出确认，新的连接就建立了。由于现在 客户端 并没有发出建立连接的请求，因此不会理睬 服务器 的确认，也不会向 服务器 发送数据。但是 服务器 却以为新的运输连接已经建立了，并一直等待 客户端 发来数据。服务器 的许多资源就这样白白浪费了。 采用三次报文握手的办法，可以防止上述现象的发生。假如在刚才的异常情况下，客户端 不会 服务器 的确认发出确认。服务器 由于收不到确认，就知道 客户端 并没有要求建立连接。

#### 四次挥手

数据传输结束后，通信的双方都可以释放资源。此时 客户端 和 服务器 都处于 **ESTABLISHED** 状态。

![](C:\Users\刘颖\Pictures\笔记\四次挥手.jpg)

**第一次握手** ： 客户端 的应用进程先向其 TCP 发出连接释放报文段，并停止在发送数据，主动关闭 TCP 连接。客户端把连接释放报文段首部的终止控制位 FIN 置 1，其序号 seq = u ,它等于前面已传过的数据的最后一个字节的序号加 1 。这时 客户端 进入 **FIN-WAIT-1 (终止等待1)** 状态，等待 服务器 的确认。（ FIN 报文段即使不携带数据，它也消耗掉一个序号。）

**第二次握手**：服务器收到连接释放报文段后即发出确认，确认号 ack = u + 1 ，而这个报文段 自己的序号是 v ,等于 服务器 前面已经传过的数据的最后一个字节的序号加 1 。然后 服务器 就进入 **CLOSEWAIT（关闭等待）**状态。TCP 服务器进程这时应通知高层应用进程（**不确定自己是否还有数据要发送给 客户端（所以是四次不是三次）**），因而从 客户端 到 服务器 这个方向的连接就释放了，这时的 TCP 连接处于 **半关闭（Half-close）**状态，即 客户端 已经没有数据要发送了，但 服务器 若发送数据，客户端仍要接收。也就是说， 服务器 到 客户端 这个方向的连接并未关闭，这个状态可能会持续一段时间。

客户端 收到来自 服务器 的确认后，就进入 **FIN-WAIT-2(终止等待2)** 状态，等待 服务器 发出的连接释放报文段。

**第三次握手**：若 服务器 已经没有要向 客户端 发送的数据，其应用进程就通知 TCP 释放连接。这时 服务器发出的连接使用报文段必须使用 FIN = 1。现假设 服务器 的序号为 w（在半关闭状态 服务器 可能又发送了一些数据）。服务器还必须重复上次已发送过的确认号 ack = u + 1。这时 服务器 就进入 **LAST-ACK (最后确认)** 状态，等待 客户端 的确认。

**第四次握手**：客户端 在收到 服务器 的连接释放报文段后，必须对此发出确认。在确认报文段中把 ACK 置 1，确认号 ack = w + 1，而自己的序号是 seq = u + 1（根据 TCP 标准，前面发送过的 FIN 报文段要消耗一个序号）。然后进入到 **TIME-WAIT(时间等待)** 状态。请注意，TCP 连接现在还没有释放掉。必须经过 **时间等待计时器（TIME-WAIT）**设置的时间 **2MSL** 后，客户端 才进入到 CLOSED 状态。时间 **MSL** 叫做 **最长报文段寿命**，RFC 793 建议设为 2 分钟。

##### 为什么 客户端 在 TIME-WAIT 状态必须等待 2MSL 的时间呢？

第一，为了保证 客户端 发送的最后一个 ACK 报文段能够到达 服务器。这个 ACK 报文段有可能丢失，因而使 服务器 收不到确认。服务器 会超时重传这个 FIN + ACK 报文段，而 客户端 就能在 2MSL 时间内收到这个重传的报文段。接着 客户端 重传一次确认，重新启动 2MSL 计时器。最后，客户端 和 服务器 都能正常进入到 **CLOSED** 状态。如果 客户端 在 TIME-WAIT 状态不等待一段时间，而是在发送完 ACK 报文段后立即释放连接，那么就无法收到 服务器 重传 的 FIN+ACK  报文段，因而也不会再发送一次确认报文段。这样，服务器 就无法按照正常步骤进入 **CLOSED** 状态。

第二，防止“已失效的连接请求报文段” 出现在本次连接中。客户端 在发送完最后一个 ACK 报文段后，再经过 2MSL，就可以使本次连接持续的时间内所产生的所有报文段都从网络中消失。这样就可以使下一个新的连接中不会出现这种旧的连接请求报文段。

##### 如果已经建立了连接，但是客户端突然出现故障了怎么办？

TCP 设有一个 **保活计时器**。服务器每收到一次客户的数据，就重新设置保活计时器，时间的设置通常是两小时。若两小时没有收到客户的数据，服务器就发送一个 探测报文段 ，以后则每隔 75 秒钟发送一次。若一连发送 10 个探测报文段后仍无客户的响应，服务器就认为客户端出了故障，接着就关闭这个连接。



### http缓存与刷新

#### 缓存

概念：将没有必要重新获取的东西再重新获取

必要性：

1、让页面加载更快一点，网络请求（几百毫秒甚至一秒）相比较 CPU计算和页面（毫秒级别）加载总是更慢，我们需要减少网络请求的体积和数量（有优化空间）

2、网络请求不稳定

#### 哪些资源可被缓存

静态资源（js css img）可以被缓存，一旦上线，就不会轻易改变。

根据文件内容生成hash值（filename:'bundle.[contenthash].js'）

html不能被缓存，时刻可能会被变更

#### 强缓存与协商缓存

##### 强制缓存

浏览器初次请求
服务器返回资源，服务端设置Cache-Control(Response Headers)，控制强制缓存的逻辑
浏览器再次请求
本地缓存返回资源

##### cache-control的值

- max-age
- no-cache 不用本地制缓存，
- no-store 不用本地缓存，也不用服务端的一些缓存
- private
- public

##### Expires

- 同在Response Headers
- 同为控制缓存过期
- 已被Cache-Control控制

##### 协商缓存（对比缓存）

- 服务端缓存策略（不是说缓存在服务端，而是服务端判断这个资源能不能用本地缓存的内容）
- 服务端判断客户端资源，是否和服务端资源一样
- 一致则返回304，否则返回200和最新的资源

###### 资源标识

- 在Response Headers
- Last-Modified 资源的最后修改时间（再次请求，Request Headers带着If-Modified-Since，值是Last-Modified）
- Etag 资源的唯一标识（一个字符串，类似于人类的指纹） Request Headers带If-None-Match

###### Last-Modified与Etag

Last-Modified与Etag可以共存
会优先使用Etag，Last-Modified只能精确到秒级
如果资源被重复生成，而内容不变，则Etag更精准

#### 三种刷新

正常操作：地址栏输入url,跳转链接，前进后退等

手动刷新：F5，点击刷新按钮，右击菜单刷新

强制刷新：ctrl+F5

#### 刷新页面对http影响

正常操作：强制缓存有效，协商缓存有效

手动刷新：强制缓存失效，协商缓存有效

强制刷新：强制缓存失效，协商缓存失效



### [CORS Cross-Origin Resource Sharing](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/CORS)

##### 基础概念

Origin:域，协议，端口

XMLHttpRequest和Fetch API遵循同源策略

##### 简单请求

##### 预检请求 preflight

OPTIONS 是 HTTP/1.1 协议中定义的方法，用以从服务器获取更多信息。该方法不会对服务器资源产生影响。 预检请求中同时携带了下面两个首部字段：

首部字段 [`Access-Control-Request-Method`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Access-Control-Request-Method) 告知服务器，实际请求将使用 POST 方法。首部字段 [`Access-Control-Request-Headers`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Access-Control-Request-Headers) 告知服务器，实际请求将携带两个自定义请求首部字段：`X-PINGOTHER` 与 `Content-Type`。服务器据此决定，该实际请求是否被允许。

###### 服务器端响应

首部字段` Access-Control-Allow-Methods `表明服务器允许客户端使用` ``POST,` `GET `和 `OPTIONS` 方法发起请求。该字段与 [HTTP/1.1 Allow: response header](https://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.7) 类似，但仅限于在需要访问控制的场景中使用。

首部字段 `Access-Control-Allow-Headers `表明服务器允许请求中携带字段 `X-PINGOTHER `与` Content-Type`。与` ``Access-Control-Allow-Methods `一样，`Access-Control-Allow-Headers` 的值为逗号分割的列表。

最后，首部字段 `Access-Control-Max-Age` 表明该响应的有效时间为 86400 秒，也就是 24 小时。在有效时间内，浏览器无须为同一请求再次发起预检请求。请注意，浏览器自身维护了一个最大有效时间，如果该首部字段的值超过了最大有效时间，将不会生效。

###### 预检请求与重定向

大多数浏览器不支持针对于预检请求的重定向。如果一个预检请求发生了重定向，浏览器将报告错误：

##### 附带身份凭证的请求

浏览器/客户端将 `XMLHttpRequest `的 `withCredentials` 标志设置为 `true`，从而向服务器发送 Cookies

因为这是一个简单 GET 请求，所以浏览器不会对其发起“预检请求”。但是，如果服务器端的响应中未携带 `Access-Control-Allow-Credentials: true` ，浏览器将不会把响应内容返回给请求的发送者。



## [浏览器渲染流程](https://juejin.cn/post/6844903565610188807)

## 性能优化（体验优化）

### 优化原则

多使用内存、缓存或者其他方法

减少cpu计算量，减少网络网络加载耗时

（适用于所有编程的性能优化——空间换时间）

### 让加载更快

减少资源体积：代码压缩

减少访问次数：合并代码，SSR服务端渲染，缓存(静态资源加hash后缀，根据文件内容计算hash)

使用更快的网络：CDN

##### 缓存

静态资源加hash后缀，根据文件内容计算hash

文件内容不变，则hash不变，则url不变

url和文件不变，则会自动触发http缓存机制，返回304

### 让渲染更快

CSS放在head，JS放在body下面

尽早开始执行JS，用DOMContentLoaded触发

懒加载（图片懒加载）

对DOM查询进行缓存

频繁操作DOM,合并到一起插入DOM结构

节流throttle 防抖debounce

##### SSR

服务器端渲染：将网页和数据一起加载，一起渲染

非SSR（前后端分离）：先加载网页，再加载数据，再渲染数据

早先的JSP ASP PHP 现在vue React SSR

##### 懒加载

先加载预览图，到露出屏幕时

#### 手写防抖、节流

##### 防抖

监听一个输入框，文字变化后触发change时间

直接用keyup事件，则会频繁触发change事件

防抖：用户输入结束或暂停时，才会触发change事件

加timer 16-7

##### 节流 throttle

拖拽一个元素时，要随时拿到该元素被拖拽的位置

直接用drag事件，则会频繁触发，很容易导致卡顿

节流：无论拖拽速度多快，都会每隔100ms触发一次

## 模块化

### CommonJS

Node.js是commonJS规范的主要实践者，它有四个重要的环境变量为模块化的实现提供支持：`module`、`exports`、`require`、`global`。实际使用时，用`module.exports`定义当前模块对外输出的接口（不推荐直接用`exports`），用`require`加载模块。

```JS
// 定义模块math.js
var basicNum = 0;
function add(a, b) {
  return a + b;
}
module.exports = { //在这里写上需要向外暴露的函数、变量
  add: add,
  basicNum: basicNum
}

// 引用自定义的模块时，参数包含路径，可省略.js
var math = require('./math');
math.add(2, 5);

// 引用核心模块时，不需要带路径
var http = require('http');
http.createService(...).listen(3000);

```

commonJS用同步的方式加载模块。在服务端，模块文件都存在本地磁盘，读取非常快，所以这样做不会有问题。但是在浏览器端，限于网络原因，更合理的方案是使用异步加载。

### AMD和require.js

AMD规范采用异步方式加载模块，模块的加载不影响它后面语句的运行。所有依赖这个模块的语句，都定义在一个回调函数中，等到加载完成之后，这个回调函数才会运行。这里介绍用require.js实现AMD规范的模块化：用`require.config()`指定引用路径等，用`define()`定义模块，用`require()`加载模块。

### CMD和sea.js

CMD是另一种js模块化方案，它与AMD很类似，不同点在于：AMD 推崇依赖前置、提前执行，CMD推崇依赖就近、延迟执行。

### ES6 Module

ES6 在语言标准的层面上，实现了模块功能，而且实现得相当简单，旨在成为浏览器和服务器通用的模块解决方案。其模块功能主要由两个命令构成：`export`和`import`。`export`命令用于规定模块的对外接口，`import`命令用于输入其他模块提供的功能。

```js
/** 定义模块 math.js **/
var basicNum = 0;
var add = function (a, b) {
    return a + b;
};
export { basicNum, add };

/** 引用模块 **/
import { basicNum, add } from './math';
function test(ele) {
    ele.textContent = add(99 + basicNum);
}
```

如上例所示，使用`import`命令的时候，用户需要知道所要加载的变量名或函数名。其实ES6还提供了`export default`命令，为模块指定默认输出，对应的`import`语句不需要使用大括号。这也更趋近于ADM的引用写法。

```js
/** export default **/
//定义输出
export default { basicNum, add };
//引入
import math from './math';
function test(ele) {
    ele.textContent = math.add(99 + math.basicNum);
}
```

ES6的模块不是对象，`import`命令会被 JavaScript 引擎静态分析，在编译时就引入模块代码，而不是在代码运行时加载，所以无法实现条件加载。也正因为这个，使得静态分析成为可能。

### [ES6与CommonJS模块的差异](https://juejin.cn/post/6844903576309858318#comment)（？引用网址评论区有不同说法

##### 1. CommonJS 模块输出的是一个值的拷贝，ES6 模块输出的是值的引用。

- CommonJS 模块输出的是值的拷贝，也就是说，一旦输出一个值，模块内部的变化就影响不到这个值。
- ES6 模块的运行机制与 CommonJS 不一样。JS 引擎对脚本静态分析的时候，遇到模块加载命令`import`，就会生成一个只读引用。等到脚本真正执行时，再根据这个只读引用，到被加载的那个模块里面去取值。换句话说，ES6 的`import`有点像 Unix 系统的“符号连接”，原始值变了，`import`加载的值也会跟着变。因此，ES6 模块是动态引用，并且不会缓存值，模块里面的变量绑定其所在的模块。

##### 2. CommonJS 模块是运行时加载，ES6 模块是编译时输出接口。

- 运行时加载: CommonJS 模块就是对象；即在输入时是先加载整个模块，生成一个对象，然后再从这个对象上面读取方法，这种加载称为“运行时加载”。
- 编译时加载: ES6 模块不是对象，而是通过 `export` 命令显式指定输出的代码，`import`时采用静态命令的形式。即在`import`时可以指定加载某个输出值，而不是加载整个模块，这种加载称为“编译时加载”。

CommonJS 加载的是一个对象（即`module.exports`属性），该对象只有在脚本运行完才会生成。而 ES6 模块不是对象，它的对外接口只是一种静态定义，在代码静态解析阶段就会生成。

## axios

官网参考https://www.npmjs.com/package/axios

### axios参数配置 

#### 配置位置

1、全局配置（**优先级最低**）

> axios.default.timeout = 3000
> axios.default.baseURL = 3000

2、实例配置

```
    let instance = axios.create()
    instance.default.timeout = 1000
```

3、axios请求时配置（**优先级最高**）

```
instance.get('/url', {
    timeout: 5000
})
```

#### 常用配置

| option  | required | remark            |
| ------- | -------- | ----------------- |
| url     | true     |                   |
| method  | false    | 默认为get         |
| baseURL | false    | 会被连接在url之前 |
| params  |          | 拼接在url之后     |
| data    |          | 放在请求体中      |

#### axios API

可以通过向 `axios` 传递相关配置来创建请求

##### axios(config)

```js
// 发送 POST 请求
axios({
  method: 'post',
  url: '/user/12345',
  data: {
    firstName: 'Fred',
    lastName: 'Flintstone'
  }
});
```

##### axios(url[, config])

```js
// 发送 GET 请求（默认的方法）
axios('/user/12345');
```

##### 请求方法的别名

为方便起见，为所有支持的请求方法提供了别名

axios.request(config)

axios.get(url[, config])

axios.delete(url[, config])

axios.head(url[, config])

axios.post(url[, data[, config]])

axios.put(url[, data[, config]])

axios.patch(url[, data[, config]])

```js
  // 检索个人报告表
  getPersonalReport (params) {
    return http.get(`${reportPrefix}personal/retrieve/`, { params })
  },
      
  // 创建团体报告
  createTeamReport (params) {
    return http.post(`${reportPrefix}team/`, params)
  },
 
  // 修改团队报告状态(发布/下架/废弃)
  setTeamStatus ({ids, status}) {
    return http.patch(`${reportPrefix}team/`, { ids, status })
  },
      

  // 修改团体报告
  updateTeamReport (params) {
    return http.put(`${reportPrefix}team/`, params)
  },
```



#### 请求配置

这些是创建请求时可以用的配置选项。只有 `url` 是必需的。如果没有指定 `method`，请求将默认使用 `get` 方法。

```js
{
  // `url` 是用于请求的服务器 URL
  url: '/user',

  // `method` 是创建请求时使用的方法
  method: 'get', // 默认是 get

  // `baseURL` 将自动加在 `url` 前面，除非 `url` 是一个绝对 URL。
  // 它可以通过设置一个 `baseURL` 便于为 axios 实例的方法传递相对 URL
  baseURL: 'https://some-domain.com/api/',


  // `transformRequest` 允许在向服务器发送前，修改请求数据
  // 只能用在 'PUT', 'POST' 和 'PATCH' 这几个请求方法
  // 后面数组中的函数必须返回一个字符串，或 ArrayBuffer，或 Stream
  transformRequest: [function (data) {
    // 对 data 进行任意转换处理
    return data;
  }],

  // `transformResponse` 在传递给 then/catch 前，允许修改响应数据
  transformResponse: [function (data) {
    // 对 data 进行任意转换处理
    return data;
  }],

  // `headers` 是即将被发送的自定义请求头
  headers: {'X-Requested-With': 'XMLHttpRequest'},

  // `params` 是即将与请求一起发送的 URL 参数
  // 必须是一个无格式对象(plain object)或 URLSearchParams 对象
  params: {
    ID: 12345
  },

  // `paramsSerializer` 是一个负责 `params` 序列化的函数
  // (e.g. https://www.npmjs.com/package/qs, http://api.jquery.com/jquery.param/)
  paramsSerializer: function(params) {
    return Qs.stringify(params, {arrayFormat: 'brackets'})
  },

  // `data` 是作为请求主体被发送的数据
  // 只适用于这些请求方法 'PUT', 'POST', 和 'PATCH'
  // 在没有设置 `transformRequest` 时，必须是以下类型之一：
  // - string, plain object, ArrayBuffer, ArrayBufferView, URLSearchParams
  // - 浏览器专属：FormData, File, Blob
  // - Node 专属： Stream

  data: {
    firstName: 'Fred'
  },

  // `timeout` 指定请求超时的毫秒数(0 表示无超时时间)
  // 如果请求花费了超过 `timeout` 的时间，请求将被中断
  timeout: 1000,
      
  // `withCredentials` 表示跨域请求时是否需要使用凭证
  withCredentials: false, // 默认的

  // `adapter` 允许自定义处理请求，以使测试更轻松
  // 返回一个 promise 并应用一个有效的响应 (查阅 [response docs](#response-api)).
  adapter: function (config) {
    /* ... */
  },

  // `auth` 表示应该使用 HTTP 基础验证，并提供凭据
  // 这将设置一个 `Authorization` 头，覆写掉现有的任意使用 `headers` 设置的自定义 `Authorization`头
  auth: {
    username: 'janedoe',
    password: 's00pers3cret'
  },
  // `responseType` 表示服务器响应的数据类型，可以是 'arraybuffer', 'blob', 'document', 'json', 'text', 'stream'
  responseType: 'json', // 默认的

  // `xsrfCookieName` 是用作 xsrf token 的值的cookie的名称
  xsrfCookieName: 'XSRF-TOKEN', // default
      
  // `xsrfHeaderName` 是承载 xsrf token 的值的 HTTP 头的名称
  xsrfHeaderName: 'X-XSRF-TOKEN', // 默认的


  // `onUploadProgress` 允许为上传处理进度事件
  onUploadProgress: function (progressEvent) {
    // 对原生进度事件的处理
  },

  // `onDownloadProgress` 允许为下载处理进度事件
  onDownloadProgress: function (progressEvent) {
    // 对原生进度事件的处理
  },

  // `maxContentLength` 定义允许的响应内容的最大尺寸
  maxContentLength: 2000,

  // `validateStatus` 定义对于给定的HTTP 响应状态码是 resolve 或 reject  promise 。如果 `validateStatus` 返回 `true` (或者设置为 `null` 或 `undefined`)，promise 将被 resolve; 否则，promise 将被 rejecte
  validateStatus: function (status) {
    return status >= 200 && status < 300; // 默认的
  },

  // `maxRedirects` 定义在 node.js 中 follow 的最大重定向数目
  // 如果设置为0，将不会 follow 任何重定向
  maxRedirects: 5, // 默认的

  // `httpAgent` 和 `httpsAgent` 分别在 node.js 中用于定义在执行 http 和 https 时使用的自定义代理。允许像这样配置选项：
  // `keepAlive` 默认没有启用

  httpAgent: new http.Agent({ keepAlive: true }),
  httpsAgent: new https.Agent({ keepAlive: true }),

  // 'proxy' 定义代理服务器的主机名称和端口
  // `auth` 表示 HTTP 基础验证应当用于连接代理，并提供凭据

  // 这将会设置一个 `Proxy-Authorization` 头，覆写掉已有的通过使用 `header` 设置的自定义 `Proxy-Authorization` 头。
  proxy: {
    host: '127.0.0.1',
    port: 9000,
    auth: : {
      username: 'mikeymike',
      password: 'rapunz3l'
    }
  },


  // `cancelToken` 指定用于取消请求的 cancel token
  // （查看后面的 Cancellation 这节了解更多）
  cancelToken: new CancelToken(function (cancel) {
  })



}
```

#### 响应结构

某个请求的响应包含以下信息

```js
{
  // `data` 由服务器提供的响应
  data: {},
      
  // `status` 来自服务器响应的 HTTP 状态码
  status: 200,

  // `statusText` 来自服务器响应的 HTTP 状态信息
  statusText: 'OK',

  // `headers` 服务器响应的头
  headers: {},

  // `config` 是为请求提供的配置信息
  config: {}
}
```







### axios请求拦截 

请求拦截器的作用是在请求发送前进行一些操作，例如在每个请求体里加上token，统一做了处理

```jsx
axios.interceptors.request.use(function (config) {
    // 在发送请求之前做些什么，例如加入token
    .......
    return config;
  }, function (error) {
    // 对请求错误做些什么
    return Promise.reject(error);
  });
```



### axios响应拦截

响应拦截器的作用是在接收到响应后进行一些操作，例如在服务器返回登录状态失效，需要重新登录的时候，跳转到登录页

```jsx
axios.interceptors.response.use(function (response) {
    // 在接收响应做些什么，例如跳转到登录页
    ......
    return response;
  }, function (error) {
    // 对响应错误做点什么
    return Promise.reject(error);
  });
```



## vue.config.js

是一个可选的配置文件

如果项目的 (和 `package.json` 同级的) 根目录中存在这个文件，那么它会被 `@vue/cli-service` 自动加载

可以使用 `package.json` 中的 `vue` 字段，但是注意这种写法需要严格遵照 JSON 的格式来写

### 选项



#### baseUrl

Vue CLI 3.3起已启用，请使用publicPath



#### publicPath 

部署应用包时的基本 URL，默认值为'/'

用法和 webpack 本身的 `output.publicPath` 一致, Vue CLI 在一些其他地方也需要用到这个值,**请始终使用 `publicPath` 而不要直接修改 webpack 的 `output.publicPath`**

这个值也可以被设置为空字符串 (`''`) 或是相对路径 (`'./'`)，这样所有的资源都会被链接为相对路径，这样打出来的包可以被部署在任意路径

##### 相对 publicPath 的限制

相对路径的 `publicPath` 有一些使用上的限制。在以下情况下，应当避免使用相对 `publicPath`:

- 当使用基于 HTML5 `history.pushState` 的路由时；
- 当使用 `pages` 选项构建多页面应用时



#### outputDir

当运行 `vue-cli-service build` 时生成的生产环境构建文件的目录。注意目标目录在构建之前会被清除 (构建时传入 `--no-clean` 可关闭该行为。

默认为'dist'

#### assetsDir

放置生成的静态资源 (js、css、img、fonts) 的 (相对于 `outputDir` 的) 目录，默认为''

#### indexPath

指定生成的 `index.html` 的输出路径 (相对于 `outputDir`)。也可以是一个绝对路径

#### filenameHashing

默认为 `true`

默认情况下，生成的静态资源在它们的文件名中包含了 hash 以便更好的控制缓存。

然而，这也要求 index 的 HTML 是被 Vue CLI 自动生成的。如果你无法使用 Vue CLI 生成的 index HTML，你可以通过将这个选项设为 `false` 来关闭文件名哈希

#### lintOnSave

设置为 `true` 或 `'warning'` 时，`eslint-loader` 会将 lint 错误输出为编译警告。默认情况下，警告仅仅会被输出到命令行，且不会使得编译失败。

如果你希望让 lint 错误在开发时直接显示在浏览器中，可以使用 `lintOnSave: 'default'`。这会强制 `eslint-loader` 将 lint 错误输出为编译错误，同时也意味着 lint 错误将会导致编译失败。

设置为 `error` 将会使得 `eslint-loader` 把 lint 警告也输出为编译错误，这意味着 lint 警告将会导致编译失败。

或者，也可以通过设置让浏览器 overlay 同时显示警告和错误。

#### transpileDependencies

Default: `[]`

默认情况下 `babel-loader` 会忽略所有 `node_modules` 中的文件。如果你想要通过 Babel 显式转译一个依赖，可以在这个选项中列出来。

#### configureWebpack

Type: `Object | Function`

如果这个值是一个对象，则会通过 webpack-merge 合并到最终的配置中。

如果这个值是一个函数，则会接收被解析的配置作为参数。该函数既可以修改配置并不返回任何东西，也可以返回一个被克隆或合并过的配置版本。

#### chainWebpack

Type: `Function`

是一个函数，会接收一个基于 web pack-chain 的 `ChainableConfig` 实例。允许对内部的 webpack 配置进行更细粒度的修改



#### devServer

所有 `webpack-dev-server` 的选项都支持。注意：

- 有些值像 `host`、`port` 和 `https` 可能会被命令行参数覆写。
- 有些值像 `publicPath` 和 `historyApiFallback` 不应该被修改，因为它们需要和开发服务器的 publicPath 同步以保障正常的工作

#### devServer.proxy

如果你的前端应用和后端 API 服务器没有运行在同一个主机上，需要在开发环境下将 API 请求代理到 API 服务器

`devServer.proxy` 可以是一个指向开发环境 API 服务器的字符串

#### parallel

Type: `boolean`

Default: `require('os').cpus().length > 1`

是否为 Babel 或 TypeScript 使用 `thread-loader`。该选项在系统的 CPU 有多于一个内核时自动启用，仅作用于生产构建。

#### pluginOptions

Type: `Object`

这是一个不进行任何 [schema验证](https://www.cnblogs.com/xudong-bupt/p/7355853.html)的对象，因此它可以用来传递任何第三方插件选项。



## ESlint

可以通过 `.eslintrc` 或 `package.json` 中的 `eslintConfig` 字段来配置

#### 配置项 实例解析

```js
module.exports = {
    root: true, //指定配置文件根目录：表示当前文件为eslint的根配置文件，逐层查找时无需往更上一级的文件目录中进行搜索
    parser: 'babel-eslint',//指定eslint解析器：babel-eslint是围绕Babel解析器的包装器使其与ESLint兼容；可能值espree、esprima
    parserOptions: { //eslint解析器配置项
        sourceType: "module",//指定js的导入方式，module是指通过模块导入，默认值为script(表示通过script标签引入)

    },
    env: { //运行环境极其局全局变量
       browser: true, //浏览器环境
    },
    plugins: [//提供插件
       'html' //插件名称，省略了[eslint-plugin-]前缀，表示规范html
   ],
    extends: 'airbnb-base', //规则继承：airbnb-base包含了JS、Es6的语法检查要依赖于[eslint-pugin-import]；另一个值standard表示使用标准的js语法规则
    
    settings: { //添加共享规则参数,会提供给每一个规则，但是规则使不使用，看规则的设置
        'import/resolver': {
               webpack: { //解析webpack配置项，路径为bulid/webpack.base.conf.js
                  config: 'bulid/webpack.base.conf.js'
              }
       }
    },
    
    
/*    针对特定文件的配置
  * 【】可以通过overrides对特定文件进行特定的eslint检测
  * 【】特定文件的路径书写使用Glob格式，一个类似正则的路径规则，可以匹配不同的文件
  * 【】配置几乎与 ESLint 的其他配置相同。覆盖块可以包含常规配置中的除了 extends、overrides 和 root 之外的其他任何有效配置选项
*/
     overrides: [
      {
       'files': ['bin/*.js', 'lib/*.js'],
       'excludedFiles': '*.test.js',
       'rules': {
        'quotes': [2, 'single']
       }
      }
     ],

    
   /* 自定义规则
    * 单条规则语法："规则名称":[规则值，规则配置] 或者 "规则名称":值
    * 基本规则值：
    off/0:关闭规则(不满足规则也不会提醒或者抛出异常)； 
    warn/1:开启警告规则(若不满足规则不会影响代码)；                                   
    error/2:开启错误规则(若不满足规则会退出代码)
   */

    rule: { //具体规则
        /* XXX/AAA: 表示xxx插件自定义的规则，省略了[eslint-plugin]前缀*/
       'import/extension': ['error','always',{ //是[eslint-plugin-import]自定义规则
              js: 'never',
             vue: 'never',
       }],
       'import/no-extraneous-dependencies': ['error',{
             optionalDependencies:['test/unit/index.js']
       }],
      'no-debugger': process.env.NODE_ENV === 'production' ? 2 : 0, //生产环境禁止使用debug模式
      'no-empty': 2, //禁止出现空语句块
      'generator-start-spacing': 0, //生成器函数*的前后空格
      'indent': 0, //缩进配置，0表示使用编辑器自带的格式化缩进
      'semi': ['error','always'], //语句强制分号，若没有分号则报错
      'space-before-function-parent': 0, //在function和()之间不需要预留空格
       }
   }
```



## [进程与线程](https://juejin.cn/post/6844903908385488903)

### 线程

线程是操作系统能够进行运算调度的最小单位，首先要清楚线程是隶属于进程的，被包含于进程之中。

**一个线程只能隶属于一个进程，但是一个进程是可以拥有多个线程的**。

#### 单线程

**单线程就是一个进程只开一个线程**

Javascript 就是属于单线程，程序顺序执行(这里暂且不提JS异步)，可以想象一下队列，前面一个执行完之后，后面才可以执行，当你在使用单线程语言编码时切勿有过多耗时的同步操作，否则线程会造成阻塞，导致后续响应无法处理。你如果采用 Javascript 进行编码时候，请尽可能的利用Javascript异步操作的特性。

### 进程

进程`Process`是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础，进程是线程的容器（来自百科）。进程是资源分配的最小单位。我们启动一个服务、运行一个实例，就是开一个服务进程，例如 Java 里的 JVM 本身就是一个进程，Node.js 里通过 `node app.js` 开启一个服务进程，多进程就是进程的复制（fork），fork 出来的每个进程都拥有自己的独立空间地址、数据栈，一个进程无法访问另外一个进程里定义的变量、数据结构，只有建立了 IPC 通信，进程之间才可数据共享。



## CDN

CDN全称是content delivery network，即内容分发网络。

#### 中心节点

中心节点包括CDN网管中心和全局负载均衡DNS重定向解析系统，负责整个CDN网络的分发及管理。

#### 边缘节点

CDN边缘节点主要指异地分发节点，由负载均衡设备、高速缓存服务器两部分组成。

#### CDN四大技术

##### 内容发布 

##### 内容存储 

##### 内容路由 

##### 内容管理



Base64URL

前面提到，Header 和 Payload 串型化的算法是 Base64URL。这个算法跟 Base64 算法基本类似，但有一些小的不同。

JWT 作为一个令牌（token），有些场合可能会放到 URL（比如 api.example.com/?token=xxx）。Base64 有三个字符`+`、`/`和`=`，在 URL 里面有特殊含义，所以要被替换掉：`=`被省略、`+`替换成`-`，`/`替换成`_` 。这就是 Base64URL 算法。





## [JWT JSON Web Token](http://www.ruanyifeng.com/blog/2018/07/json_web_token-tutorial.html)

#### 使用方式

客户端收到服务器返回的 JWT，可以储存在 Cookie 里面，也可以储存在 localStorage

可以把它放在 Cookie 里面自动发送，但是这样不能跨域

​	另一种做法，跨域的时候，JWT放在post请求的数据体里。

更好的做法是放在 HTTP 请求的头信息`Authorization`字段里面

#### 数据结构

##### 三个部分

- Header（头部）
- Payload（负载）
- Signature（签名）

#### 特点

默认不加密，但也可以加密。生成原始 Token 以后，可以用密钥再加密一次

JWT 不加密的情况下，不能将秘密数据写入 JWT

JWT 不仅可以用于认证，也可以用于交换信息。有效使用 JWT，可以**降低服务器查询数据库的次数**

一旦 JWT 签发了，在到期之前就会始终有效，除非服务器部署额外的逻辑

为了减少盗用，JWT 的有效期应该设置得比较短。对于一些比较重要的权限，使用时应该再次对用户进行认证。

为了减少盗用，JWT 不应该使用 HTTP 协议明码传输，要使用 HTTPS 协议传输

## 单点登录 single sign on

#### 定义

在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统。



## 文件下载

#### 通过文件地址直接下载

在页面中放一个**a标签**，**href**上是**文件路径**，并写上**download**属性。

相当于一个get请求，浏览器直接访问该静态资源

download告诉浏览器此a标签不是打开页面预览，而是进行下载。

地址后绑定在**a标签**中或者通过**window.open()**都可以进行下载

#### [二进制流文件下载](https://juejin.cn/post/6878912072780873742#comment)

##### 基本特征

实际项目使用的ajax请求接口方式，比如post请求，前端传递若干参数，后端返回文件二进制流。

##### 服务器设置

res.writeHead(

)

Content-type

##### 前端客户端发送请求设置

responseType: "arraybuffer" // arraybuffer是js中提供处理二进制的接口

拿到返回数据后，将二进制数据生成一个文件url，用URL.createObjectURL生成url时需要传入Blob类型的参数。



#### Blob构造函数

**IE10**的window.navigator.msSaveBlob和window.navigator.msSaveOrOpenBlob

```js
//创建
var blobObject = new Blob(["I scream. You scream. We all scream for ice cream."]); 
```

1.msSaveBlob：只提供一个保存按钮

```js
window.navigator.msSaveBlob(blobObject, 'msSaveBlob_testFile.txt');
```

2.msSaveOrOpenBlob：提供保存和打开按钮

```js
window.navigator.msSaveOrOpenBlob(blobObject, 'msSaveBlobOrOpenBlob_testFile.txt');
```







## [跨域CORS](https://juejin.cn/post/6844903929508003853#heading-0)

跨域是**浏览器**的限制

### 处理方案

#### 服务器端配合设置响应头

##### 对于简单请求

指明允许哪些访问源访问 Access-Control-Allow-Origin

##### 对于非简单请求

设置允许请求的方法 Access-Control-Allow-Methods

非简单请求还对请求头的信息有所限制，通过`Access-Control-Allow-Headers`在返回头中设置允许的访问头就ok

#### jsonp

使用script标签的src不受浏览器跨域限制的原理

jsonp只能发送get请求

前端定义一个函数来接收返回的数据，后端返回的内容中调用这个函数，把数据传进去，函数名要前后端约定一致。

获取完数据最好移除一下script标签。





#### Proxy



### git

git  commit是提交到本地仓库，然后push， 先commit再pull再push目的：

应对多人合并开发commit 告诉git这次提交修改了那些东西，不然只是自己知道改了，但是git不知道。

pull是把本地commit和远程commit的提交对比记录，git按照问卷的行数对比，如果同时操作某文件的同一行就会发生冲突，git把这个冲突标记出来。

让pull的人 和冲突的人 决定保留谁的代码 之后再 add commit pull三连，再次pull防止协商的时候另一个人又提交了一版东西。 

A->B B分支会产生一个merge_commit信息，B是合并状态，A是未合并状态。 

#### 单人提交基本流程 

untracked 表示git仓库对它没有进行任何记录

add以后 untracked—>staged 被记录进暂存区 英文中有一个意义：用来汇集物品或材料已备使用的区域。 ——集中收集改动以待

提交 commit后 成功做一次提交到本地仓库，它已经被保存在.git这个目录的某个地方 

> git clone 链接地址 xx自定义本地仓库的根目录名称项目名称 

#### 团队合作基本模型 

git的push其实是用本地从选哪个库的commits记录覆盖远端commits记录， 由于 GitHub 的远端仓库上含有本地仓库没有的内容，所以`push` 会被拒绝。

这种冲突的解决方式其实很简单：**先用** `pull` 把远端仓库上的新内容取回到本地和本地合并，然后再把合并后的本地仓库向远端仓库推送。  

「多人合作的基本工作模型」改良：

1. 写完所有的 `commit` 后，不用考虑中央仓库是否有新的提交，直接 `push` 就好
2. 如果 `push` 失败，就用 `pull` 把本地仓库的提交和中央仓库的提交进行合并，然后再 `push` 一次



#### 基于 branch 的工作模型

##### checkout 

签出，把某个commit当做当前commit，把HEAD移动过去并把工作目录的文件内容替换成这个commit所对应的内容

##### branch

###### 创建branch

git branch xxx分支名

###### 切换分支checkout

git checkout xx分支名

###### 创建并切换 

git checkout -b xx分支名 是创建与切换的合并执行，用指定名称创建后直接切换过去

###### 查看分支情况

git branch -a



###### 删除

git branch -d xx分支名

> 1、HEAD指向的branch不能删除，如果要删除HEAD指向的branch，需要先用checkout把HEAD指向其他地方
>
> 2、由于 Git 中的 `branch` 只是一个引用，所以删除 `branch` 的操作也只会删掉这个引用，并不会删除任何的 `commit`。（不过如果一个 `commit` 不在任何一个 `branch` 的「路径」上，或者换句话说，如果没有任何一个 `branch` 可以回溯到这条 `commit`（也许可以称为野生 `commit`？），那么在一定时间后，它会被 Git 的回收机制删除掉。
>
> 3、出于安全考虑，没有被合并到 `master` 过的 `branch` 在删除时会失败（因为怕你误删掉「未完成」的 `branch` 啊）
>
> 如果你确认是要删除这个 `branch` （例如某个未完成的功能被团队确认永久毙掉了，不再做了），可以把 `-d` 改成 `-D`，小写换成大写，就能删除了

所谓「引用」（reference），其实就是一个个的字符串。这个字符串可以是一个 `commit` 的 SHA-1 码（例：`c08de9a4d8771144cd23986f9f76c4ed729e69b0 3200902201408160057 320584ch20181020011x`  ），也可以是一个 `branch`（例：`ref: refs/heads/feature3`）。

Git 中的 `HEAD` 和每一个 `branch` 以及其他的引用，都是以文本文件的形式存储在本地仓库 `.git` 目录中，而 Git 在工作的时候，就是通过这些文本文件的内容来判断这些所谓的「引用」是指向谁的。

##### pull两步走

1、git fetch下载远端代码仓库内容

2、操作merge的目标commit

##### push本质

1. `push` 是把当前的分支上传到远程仓库，并把这个 `branch` 的路径上的所有 `commit`s 也一并上传。
2. `push` 的时候，如果当前分支是一个本地创建的分支，需要指定远程仓库名和分支名，用 `git push origin branch_name` 的格式，而不能只用 `git push`；或者可以通过 `git config` 修改 `push.default` 来改变 `push` 时的行为逻辑。
3. `push` 的时候之后上传当前分支，并不会上传 `HEAD`；远程仓库的 `HEAD` 是永远指向默认分支（即 `master`）的。

##### merge 合并commits

`pull` 的内部操作其实是把远程仓库取到本地后（使用的是 `fetch`），再用一次 `merge` 来把远端仓库的新 `commits` 合并到本地

##### 放弃解决冲突，取消 merge？

当现在 Git 仓库处于冲突待解决的中间状态，如果最终决定放弃这次 `merge`，也需要执行一次 `merge --abort` 来手动取消它：

```
git merge --abort
```



##### origin/master 和 origin/HEAD

它们是对远端仓库的master和HEAD的本地镜像。



#### Feature Branching

这种工作流的核心内容

1. 任何新的功能（feature）或 bug 修复全都新建一个 `branch` 来写；
2. `branch` 写完后，合并到 `master`，然后删掉这个 `branch`。

解决问题

代码分享和一人多任务



##### pull request



### 从输入URL到页面加载完成，发生了什么？

> 从输入URL到页面加载完成，发生了什么？

首先通过 DNS（域名解析系统）将 URL 解析为对应的 IP 地址

然后与这个 IP 地址确定的那台服务器建立起 TCP 网络连接

随后向服务端抛出 HTTP 请求

服务端处理完我们的请求之后，把目标数据放在 HTTP 响应里返回给客户端

拿到响应数据的浏览器就可以开始走一个渲染的流程

渲染完毕，页面便呈现给了用户，并时刻等待响应用户的操作

![](https://user-gold-cdn.xitu.io/2018/10/18/16685737b823244c?w=489&h=329&f=png&s=19023)

将这个过程切分为如下的过程片段：

1.  DNS 解析
2.  TCP 连接
3.  HTTP 请求抛出
4.  服务端处理请求，HTTP 响应返回
5.  浏览器拿到响应数据，解析响应内容，把解析的结果展示给用户

任何一个用户端的产品，都需要把这 5 个过程滴水不漏地考虑到自己的性能优化方案内、反复权衡，从而打磨出用户满意的速度。



DNS 解析花时间，能不能尽量减少解析次数或者把解析前置？

​	能——浏览器 DNS 缓存和 DNS prefetch。

TCP 每次的三次握手都急死人，有没有解决方案？

​	有——长连接、预连接、接入 SPDY 协议。

那么 HTTP 请求呢？

​	——在减少请求次数和减小请求体积方面，前端应该是专家！再者，服务器越远，一次请求就越慢，那部署时就把静态资源放在更近的 CDN 上是不是就能更快一些？

以上提到的都是网络层面的性能优化。

再往下走就是浏览器端的性能优化——这部分涉及资源加载优化、服务端渲染、浏览器缓存机制的利用、DOM 树的构建、网页排版和渲染过程、回流与重绘的考量、DOM 操作的合理规避等等——这正是前端工程师可以真正一展拳脚的地方。



整个的知识图谱，用思维导图展示如下：

![](https://user-gold-cdn.xitu.io/2018/10/23/1669f5358f63c0f8?w=2478&h=1506&f=png&s=340672)



### http优化

##### 优化大方向

*   减少请求次数
*   减少单次请求所花费的时间

指向资源的**压缩与合并**——构建工具所做之事——当前最主流的构建工具是webpack

#### webpack

##### webpack优化瓶颈

*   webpack 的构建过程太花时间
*   webpack 打包的结果体积太大

webpack是单线程的

##### 构建过程提速

##### 构建结果体积压缩

###### 文件结构可视化，找出导致体积过大的原因

一个非常好用的包组成可视化工具——[webpack-bundle-analyzer](https://www.npmjs.com/package/webpack-bundle-analyzer)，配置方法和普通的 plugin 无异，它会以矩形树图的形式将包内各个模块的大小和依赖关系呈现出来，格局如官方所提供这张图所示：

![](https://user-gold-cdn.xitu.io/2018/9/14/165d838010b20a4c?w=908&h=547&f=gif&s=3663774)

在使用时，只需要将其以插件的形式引入：

```js
const BundleAnalyzerPlugin = require('webpack-bundle-analyzer').BundleAnalyzerPlugin;
 
module.exports = {
  plugins: [
    new BundleAnalyzerPlugin()
  ]
}
```

#### gzip

开启 Gzip。

具体的做法非常简单，只需要你在你的 request headers 中加上这么一句：

```
accept-encoding:gzip
```

聊一个和前端关系更密切的话题：HTTP 压缩。

> HTTP 压缩是一种内置到网页服务器和网页客户端中以改进传输速度和带宽利用率的方式。在使用 HTTP 压缩的情况下，HTTP 数据在从服务器发送前就已压缩：兼容的浏览器将在下载所需的格式前宣告支持何种方法给服务器；不支持压缩方法的浏览器将下载未经压缩的数据。最常见的压缩方案包括 Gzip 和 Deflate。

以上是摘自百科的解释，事实上，大家可以这么理解：

**HTTP 压缩就是以缩小体积为目的，对 HTTP 内容进行重新编码的过程**

Gzip 的内核就是 Deflate，目前我们压缩文件用得最多的就是 Gzip。可以说，Gzip 就是 HTTP 压缩的经典例题。

###### 该不该用 Gzip

如果你的项目不是极端迷你的超小型文件，都建议你试试 Gzip。

有的同学或许存在这样的疑问：压缩 Gzip，服务端要花时间；解压 Gzip，浏览器要花时间。中间节省出来的传输时间，真的那么可观吗？

答案是肯定的。如果手上的项目是 1k、2k 的小文件，那确实有点高射炮打蚊子的意思，不值当。但更多的时候，我们处理的都是具备一定规模的项目文件。实践证明，这种情况下压缩和解压带来的时间开销相对于传输过程中节省下的时间开销来说，可以说是微不足道的。

###### Gzip 是万能的吗

首先要承认 Gzip 是高效的，压缩后**通常**能帮我们减少响应 70% 左右的大小。

但它并非万能。Gzip 并不保证针对每一个文件的压缩都会使其变小。

Gzip 压缩背后的原理，是在一个文本文件中找出一些重复出现的字符串、临时替换它们，从而使整个文件变小。根据这个原理，文件中代码的重复率越高，那么压缩的效率就越高，使用 Gzip 的收益也就越大。反之亦然。

###### webpack 的 Gzip 和服务端的 Gzip

一般来说，Gzip 压缩是服务器的活儿：服务器了解到这边有一个 Gzip 压缩的需求，它会启动自己的 CPU 去完成这个任务。而压缩文件这个过程本身是需要耗费时间的，大家可以理解为 以服务器压缩的时间开销和 CPU 开销（以及浏览器解析压缩文件的开销）为代价，省下了一些传输过程中的时间开销。

### 浏览器

#### [浏览器储存](https://juejin.cn/post/6950265675159978021)

Web存储（Web Storage）：HTML5提出的存储方式，容量有 5M。

- localStorage
- sessionStorage

Cookie 浏览器普遍支持的基于http协议的存储方式，容量只有4KB

数据库存储：IndexDB Web SQL

##### Cookie

###### 构成

- 名称（Name）
- 值（Value）
- 域（Domain）
- 路径（Path）
- 失效时间 （Expiers/Max-Age）
- 大小（Size）
- 是否为 HTTP请求（HttpOnly）
- 安全性（Secure）

> 域、路径、失效时间和安全性都是**服务器给浏览器**的指示，它们不会随着请求发送给服务器，发送给服务器的只有名称与值对。

###### 限制

- 如果设定了 Cookie 的过期时间，那么 Cookie 会在到期时自动失效。
- 如果没有设定过期时间，那么 Cookie 就是 session 级别的，即浏览器关闭时 Cookie 自动消失

###### 优缺点

**优点：**

1. 可以控制过期时间，不会永久有效，有一定的安全保障。
2. 可进行扩展，可跨域共享。
3. 通过加密与安全传输技术 （SSL） ，可以减少 Cookie 被破解的可能性。
4. 有较高的兼容性。

**缺点：**

1. 有一定的数量与长度限制，每个 Cookie 长度不能超过 4 KB ，否则超出部分会被截掉。
2. 请求头上的数据容易被拦截攻击。

###### 产生

1. 在浏览器访问服务器时由服务器返回一个Set-Cookie响应头，当浏览器解析这个响应头时设置cookie
2. 通过浏览器js脚本设置`document.cookie = 'name=monsterooo';`浏览器访问服务器携带cookie过程



##### WebStorage

###### 出现原因

- 克服 Cookie 的一些限制，同时存储一些需要严格控制在客户端，不需要发送给服务器的一些数据。
- 提供了除 Cookie 之外的另一种存储会话的途径。
- 提供了一种大容量存储空间来跨回话存储数据的途径。

它们都是**直接作为 window对象的属性**存在的，我们可以直接通过 window.localStorage 与 window.sessionStorage 来访问。

注： Web Storage 只能储存字符串，如果用 Web Storage 存储对象，会出现 [Object Object], 可以用 **JSON.stringify** 与 **JSON.parse**方法来解决这个问题。

###### 实例方法

- clear：删除所有值
- getItem(name): 根据传入的键来获取对应的值。
- key(index): 获得所对应索引的键，名称。
- removeItem(name): 删除键对应的键值对
- setItem(name, value): 为指定的 name 设置一个对应的值

###### sessionStorage

> - 同源策略： 不同于 Cookie， sessionStorage 访问限制更高，只有当前设定了 sessionStorage 的域下才能访问。
> - 单标签页： 两个相同域下的标签页不能**互通**。
> - 在关闭标签页或者新开的标签页下都不能访问之前写下的 sessionStorage, 刷新标签页依然可以访问 sessionStorage。
>
> **使用场景：**
>
> 1. 主要针对会话级的小数据的存储。
> 2. 存储一些在当前页面刷新仍然需要存储，但是关闭后不需要留下的信息。
> 3. 很适合单页应用的使用，可以用来存储登录态信息等。

###### localStorage

> - 同源策略：和 sessionStorage 一样，要访问同一个 localStorage 页面必须来自同一个域名，同种协议，同种端口。
> - localStorage 设定后，刷新或者重新打开标签页，关闭浏览器重新打开原来的标签页也可以访问到。

> **使用场景：**
>
> 1. 持久性的保存客户端数据，只能通过 JavaScript 删除或者用户清除浏览器缓存。
> 2. 如果有一些稍大量的数据，例如编辑器的**自动保存**等。
> 3. 多页面间访问共同数据。 sessionStorage 只能用于一个标签页，而localStorage可以在多个标签页之间共享。

###### sessionStorage 与 localStorage 的区别

> - 生命周期：localStorage 是本地存储，没有期限，只能用户自己操作来删除。 sessionStroage 是会话存储，页面关闭数据就会丢失。
> - sessionStorage 有单标签页的限制，localStorage则没有。



###### Storage 事件

> 我们对 Storage 对象进行任何的操作，都会在文档上触发 Storage 事件， 这个事件的 event 对象有以下属性：
>
> - domain：发生变化的存储空间的域名。
> - key：设置或删除的键名
> - newValue： 如果是设置值，则是新值。如果是删除键，则为null。
> - oldValue：键被更改之前的值。

##### [IndexDB 与 Web SQL](https://juejin.cn/post/6844903815620100110#heading-18)

#### 缓存

##### Cache Storage

在 Service Worker 的规范中提出，一般配合 Service Worker 进行离线缓存。

`Cache Storage` 是用来存储 `Response` 对象 ，也就是对 HTTP 响应进行缓存。 `Cache Storage` 是多个 `cache` 的集合，每个 `cache` 可以存储多个响应对象。它基于 Promise。

##### Application Cache

在 HTML5.1提出的缓存方式，可用来构建离线应用。

优点:

- 离线浏览
- 提升页面的载入速度
- 降低服务器的压力

一般来说 `Application Cache` 只用来存储一些静态资源，它的使用方式主要需要两个步骤：

1.服务端维护一个 `manifest`清单

2.浏览器端进行一个设置。

```html
<html manifest="demo">
```

> 一般的，我们必须给 manifest 文件设置正确的 MIME-type 为 "text/cache-manifest"，它需要在服务器端进行配置。

在 Progressive Web Application 中， Application Cache 配合 Service Worker 承担着主要的任务。










#### 浏览器安全

##### 同源政策（浏览器最核心也最基本的安全功能

如果两个 URL 的**协议**、**域名**和**端口**都相同，就称这两个 URL 同源。

两个不同的源之间若想要相互访问资源或者操作 DOM，那么会有一套基础的安全策略的制约，这称为同源策略。

- DOM 层面：限制了来自不同源的 JavaScript 脚本对当前 DOM 对象读和写的操作。 DOM无法获得
- 数据层面：限制了不同源的站点读取当前站点的 Cookie、IndexDB、LocalStorage 等数据。
- 网络层面：限制了通过 XMLHttpRequest 等方式将站点的数据发送给不同源的站点。 AJAX请求不能发送

以下三个标签不受限制

- `<img src=XXX>`
- `<link href=XXX>`
- `<script src=XXX>`

##### 没有同源政策的情景模拟

一、如果没有 DOM 同源策略，也就是说不同域的 iframe 之间可以相互访问，那么黑客可以这样进行攻击

1. 做一个假网站，里面用 iframe 嵌套一个银行网站 `http://mybank.com`。
2. 把 iframe 宽高啥的调整到页面全部，这样用户进来除了域名，别的部分和银行的网站没有任何差别。
3. 这时如果用户输入账号密码，我们的主网站可以跨域访问到 `http://mybank.com` 的 dom 节点，就可以拿到用户的账户密码了。

二、如果 XMLHttpRequest 同源策略，那么黑客可以进行 CSRF（跨站请求伪造） 攻击：

1. 用户登录了自己的银行页面 `http://mybank.com`，`http://mybank.com` 向用户的 cookie 中添加用户标识。
2. 用户浏览了恶意页面 `http://evil.com`，执行了页面中的恶意 AJAX 请求代码。
3. `http://evil.com` 向 `http://mybank.com` 发起 AJAX HTTP 请求，请求会默认把 `http://mybank.com` 对应 cookie 也同时发送过去。
4. 银行页面从发送的 cookie 中提取用户标识，验证用户无误，response 中返回请求数据。此时数据就泄露了。
5. 而且由于 Ajax 在后台执行，用户无法感知这一过程。

##### XMLHttpResponse不能跨域请求资源

存在同源政策，不同源的资源请求会被制止

使用XMLHttpRequest无法直接进行跨域请求，浏览器在严格策略的基础之上引入跨域资源共享策略，让其可以安全进行跨域操作

##### 安全与便利权衡

1、页面中可以嵌入第三方资源。->XSS攻击

- 为了解决 XSS 攻击，浏览器中引入了**内容安全策略**，称为 CSP。
- CSP 的**核心思想**是让服务器决定浏览器能够加载哪些资源，让服务器决定浏览器是否能够执行内联 JavaScript 代码。
- 通过这些手段就可以大大减少 XSS 攻击。

2、跨域资源共享

- 使用 XMLHttpRequest 和 Fetch 都是无法直接进行跨域请求的，因此浏览器又在这种严格策略的基础之上引入了跨域资源共享策略，让其可以安全地进行跨域操作。
- **跨域资源共享（CORS）**，使用该机制可以进行跨域访问控制，从而使跨域数据传输得以安全进行。

3、跨文档消息机制

- 两个不同源的DOM是不能互相操纵的，因此浏览器又实现了**跨文档消息机制**，可以通过 window.postMessage 的 JavaScript 接口来和不同源的 DOM 进行通信。

##### 常见web前端攻击方式

###### XSS跨站请求攻击

一个博客网站，我发表一篇博客，其中嵌入`<script>`脚本

脚本内容：获取cookie，发送到我的服务器（服务器配合跨域）

发布这篇博客，有人查看它，我轻松收割访问者的cookie

###### XSS预防

替换特殊字符，如<变为< >变为>`<script>`变为`<script>` 直接显示，而不会作为脚本执行，可以使用xss替换工具

充分利用CSP

- 限制加载其他域下的资源文件，这样即使黑客插入了一个 JavaScript 文件，这个 JavaScript 文件也是无法被加载的；
- 禁止向第三方域提交数据，这样用户数据也不会外泄；
- 禁止执行内联脚本和未授权的脚本；
- 还提供了上报机制，这样可以帮助我们尽快发现有哪些 XSS 攻击，以便尽快修复问题。

使用HttpOnly属性

验证码——防止脚本冒充用户提交危险操作

限制长度——对于一些不信任的输入，还可以限制其输入长度

###### XSRF 跨站请求伪造攻击

利用服务器的漏洞和用户的登录状态来实施攻击。

我已经登录了

邮件正文隐藏

`<img>`发送的请求可以支持跨域

###### XSRF预防

1、使用post接口

2、增加验证，例如密码、短信验证码、指纹等

3、**充分利用好 Cookie 的 SameSite 属性** SameSite的三种属性

- Strict 最为严格，浏览器会完全禁止第三方 Cookie。
- Lax 相对宽松一点。链接打开、 Get 方式的表单携带 Cookie。
- None ，在任何情况下都会发送 Cookie 数据。

4、**验证请求的来源站点** Post请求时的Origin信息

5、CSRF Token

- 第一步，在浏览器向服务器发起请求时，服务器生成一个 CSRF Token。
- 第二步，在浏览器端如果要发起转账的请求，那么需要带上页面中的 CSRF Token，然后服务器会验证该 Token 是否合法。

6.X-FRAME-OPTIONS

- DENY，表示页面不允许通过iframe方式展示
- SAMEORIGIN，相同域名可以·通过ifame展示
- ALLOW-FROM，可以在指定来源中的iframe展示



#### [跨域](https://juejin.cn/post/6844903859068862472)

##### CORS（Cross-origin resource sharing）跨域资源共享机制

除jsonp之外最常用的跨域方式之一，是W3C标准，跨域资源共享。

允许浏览器向跨源服务器发出XMLHttpRequest请求，克服ajax只能同源使用的限制。

`CORS`是跨源`AJAX`请求的根本解决方法。`JSONP`只能发`GET`请求，但是`CORS`允许任何类型的请求。

整个`CORS`通信过程都是浏览器自动完成的，不需要用户参与。对于开发者来说，`CORS`通信与同源的`AJAX`通信没有差别，代码完全一样。**浏览器一旦发现AJAX请求跨源，就会自动添加一些附加的头信息，有时还会多一次附加的请求，但用户不会有感觉**。因此，实现`CORS`通信的关键是**服务器**。只要服务器实现了`CORS`接口，就可以跨源通信。

###### 与JSONP的比较

`CORS`与`JSONP`的使用目的相同，但是比`JSONP`更强大。

`JSONP`只支持`GET`请求，`CORS`支持所有类型的`HTTP`请求。`JSONP`的优势在于支持老式浏览器，以及可以向不支持`CORS`的网站请求数据。

##### JSONP

JSONP 的原理很简单，就是利用 `<script>` 标签没有跨域限制的漏洞。通过 `<script>` 标签指向一个需要访问的地址并提供一个回调函数来接收数据当需要通讯时。

```JS
<script src="http://domain/api?param1=a&param2=b&callback=jsonp"></script>
<script>
    function jsonp(data) {
    	console.log(data)
	}
</script>    
```



#### [垃圾回收 Garbage Collection](https://juejin.cn/post/6981588276356317214#heading-6)

垃圾回收机制是由**引擎**来做

垃圾：程序不用的**内存**或者之前用过，但是以后不会再用的内存空间

垃圾回收机制的原理：定期找出那些不再用到的内存（变量）然后释放内存

##### 垃圾回收策略

###### 标记清除算法

- 垃圾收集器在运行时会给内存中的所有变量都加上一个标记，假设内存中所有对象都是垃圾，全标记为0
- 然后从各个根对象开始遍历，把不是垃圾的节点改成1
- 清理所有标记为0的垃圾，销毁并回收它们所占用的内存空间
- 最后，把所有内存中对象标记修改为0，等待下一轮垃圾回收

优点：实现比较简单

缺点：内存碎片化、分配速度慢

###### 引用技术算法

把 `对象是否不再需要` 简化定义为 `对象有没有其他对象引用到它`，如果没有引用指向该对象（零引用），对象将被垃圾回收机制回收，目前很少使用这种算法了，因为它的问题很多。

它的策略是跟踪记录每个变量值被使用的次数

- 当声明了一个变量并且将一个引用类型赋值给该变量的时候这个值的引用次数就为 1
- 如果同一个值又被赋给另一个变量，那么引用数加 1
- 如果该变量的值被其他的值覆盖了，则引用次数减 1
- 当这个值的引用次数变为 0 的时候，说明没有变量在使用，这个值没法被访问了，回收空间，垃圾回收器会在运行的时候清理掉引用次数为 0 的值占用的内存

#### 执行机制

##### 浏览器内核

浏览器内核决定浏览器解释网页语法的方式。

###### 两部分

渲染引擎和JS引擎，随着JS引擎越来越独立，内核成了渲染引擎的代称。渲染引擎又包括了 HTML 解释器、CSS 解释器、布局、网络、存储、图形、音视频、图片解码器等等零部件。

###### 常见浏览器内核

Trident（IE）、Gecko（火狐）、Blink（Chrome、Opera）、Webkit（Safari）



#### [浏览器渲染](https://juejin.cn/post/6844903565610188807)

注意 少**层叠，嵌套**

当解析html的时候，会把新来的元素插入dom树里面，同时去查找css，然后把对应的样式规则应用到元素上，查找样式表是按照**从右到左**的顺序去匹配的。

例如： div p {font-size: 16px}，会先寻找所有p标签并判断它的父标签是否为div之后才会决定要不要采用这个样式进行渲染）。

所以，平时写CSS时，尽量用id和class，不要**过渡层叠**

##### 关键渲染路径

关键渲染路径是指浏览器从最初接收请求来的HTML、CSS、javascript等资源，然后解析、构建树、渲染布局、绘制，最后呈现给客户能看到的界面这整个过程。

所以浏览器的渲染过程主要包括以下几步：

1. 解析HTML生成DOM树。
2. 解析CSS生成CSSOM规则树。
3. 将DOM树与CSSOM规则树合并在一起生成渲染树。
4. 遍历渲染树开始布局，计算每个节点的位置大小信息。
5. 将渲染树每个节点绘制到屏幕。

##### 几棵重要的“树”

为了使渲染过程更明晰一些，我们需要给这些”树“们一个特写:

![](https://user-gold-cdn.xitu.io/2018/9/27/16619d637d220b20?w=1018&h=377&f=png&s=45067)

*   DOM 树：解析 HTML 以创建的是 DOM 树（DOM tree ）：渲染引擎开始解析 HTML 文档，转换树中的标签到 DOM 节点，它被称为“内容树”。

*   CSSOM 树：解析 CSS（包括外部 CSS 文件和样式元素）创建的是 CSSOM 树。CSSOM 的解析过程与 DOM 的解析过程是**并行的**。

*   渲染树：CSSOM 与 DOM 结合，之后我们得到的就是渲染树（Render tree ）。

*   布局渲染树：从根节点递归调用，计算每一个元素的大小、位置等，给每个节点所应该出现在屏幕上的精确坐标，我们便得到了基于渲染树的布局渲染树（Layout of the render tree）。

*   绘制渲染树: 遍历渲染树，每个节点将使用 UI 后端层来绘制。整个过程叫做绘制渲染树（Painting the render tree）。

基于这些“树”，我们再梳理一番：

渲染过程说白了，首先是基于 HTML 构建一个 DOM 树，这棵 DOM 树与 CSS 解释器解析出的 CSSOM 相结合，就有了布局渲染树。最后浏览器以布局渲染树为蓝本，去计算布局并绘制图像，由此页面的初次渲染就大功告成了。

之后每当一个新元素加入到这个 DOM 树当中，浏览器便会通过 CSS 引擎查遍 CSS 样式表，找到符合该元素的样式规则应用到这个元素上，然后再重新去绘制它。

查表是个花时间的活，怎么让浏览器的查询工作又快又好地实现呢？引出了第一个可转化为代码的优化点——CSS 样式表规则的优化！

###### 基于渲染流程的 CSS 优化建议

CSS 选择符是从右到左进行匹配的。

* 避免使用通配符，只对需要用到的元素进行选择。

* 关注可以通过继承实现的属性，避免重复匹配重复定义。

* 少用标签选择器。如果可以，用类选择器替代，举个🌰：

  错误示范：

  ```css
  #myList li{}
  ```

  课代表：

  ```css
  .myList_li {}
  ```

* 不要画蛇添足，id 和 class 选择器不应该被多余的标签选择器拖后腿。举个🌰：

  错误示范

  ```
  .myList#title
  ```

  课代表

  ```css
  #title
  ```

* 减少嵌套。**后代选择器的开销最高**的，因此应该尽量将选择器的深度降到最低（最高不要超过三层），尽可能使用类来关联每一个标签元素。

###### 告别阻塞：CSS 与 JS 的加载顺序优化

说完过程，来说特性。

HTML、CSS 和 JS，都具有**阻塞渲染**的特性。

HTML 阻塞，天经地义——没有 HTML，何来 DOM？没有 DOM，渲染和优化，都是空谈

**CSS 的阻塞**

在刚刚的过程中，DOM 和 CSSOM 合力才能构建渲染树。这一点会给性能造成严重影响：默认情况下，CSS 是阻塞的资源。浏览器在构建 CSSOM 的过程中，**不会渲染任何已处理的内容**。即便 DOM 已经解析完毕，只要 CSSOM 不 OK，那么渲染这个事情就不 OK（这主要是为了避免没有 CSS 的 HTML 页面丑陋地“裸奔”在用户眼前）。

我们知道，只有当我们开始解析 HTML 后、解析到 link 标签或者 style 标签时，CSS 才登场，CSSOM 的构建才开始。很多时候，DOM 不得不等待 CSSOM。因此可以这样总结：

> CSS 是阻塞渲染的资源。需要将它尽早、尽快地下载到客户端，以便缩短首次渲染的时间。

事实上，现在很多团队都已经做到了尽早（将 CSS 放在 head 标签里）和尽快（启用 CDN 实现静态资源加载速度的优化）。这个“把 CSS 往前放”的动作，对很多同学来说已经内化为一种编码习惯。那么现在我们还应该知道，这个“习惯”不是空穴来风，它是由 CSS 的特性决定的。

**JS 的阻塞**

在首次渲染过程中，JS 并不是一个非登场不可的角色——没有 JS，CSSOM 和 DOM 照样可以组成渲染树，页面依然会呈现——即使它死气沉沉、毫无交互。

JS 的作用在于**修改**，它帮助我们修改网页的方方面面：内容、样式以及它如何响应用户交互。这“方方面面”的修改，本质上都是对 DOM 和 CSSDOM 进行修改。因此 JS 的执行会阻止 CSSOM，在不作显式声明的情况下，它也会阻塞 DOM。

我们通过一个🌰来理解一下这个机制：

```html
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>JS阻塞测试</title>
  <style>
    #container {
      background-color: yellow;
      width: 100px;
      height: 100px;
    }
  </style>
  <script>
    // 尝试获取container元素
    var container = document.getElementById("container")
    console.log('container', container)
  </script>
</head>
<body>
  <div id="container"></div>
  <script>
    // 尝试获取container元素
    var container = document.getElementById("container")
    console.log('container', container)
    // 输出container元素此刻的背景色
    console.log('container bgColor', getComputedStyle(container).backgroundColor)
  </script>
  <style>
    #container {
      background-color: blue;
    }
  </style>
</body>
</html>
```

三个 console 的结果分别为：

![](https://user-gold-cdn.xitu.io/2018/9/28/166203a2d62212c9?w=1050&h=254&f=png&s=27323)

注：本例仅使用了内联 JS 做测试。感兴趣的同学可以把这部分 JS 当做外部文件引入看看效果——它们的表现一致。

第一次尝试获取 id 为 container 的 DOM 失败，这说明 **JS 执行时阻塞了 DOM，后续的 DOM 无法构建**；第二次才成功，这说明脚本块只能找到在它前面构建好的元素。这两者结合起来，“阻塞 DOM”得到了验证。再看第三个 console，尝试获取 CSS 样式，获取到的是在 JS 代码执行前的背景色（yellow），而非后续设定的新样式（blue），说明 CSSOM 也被阻塞了。那么在阻塞的背后，到底发生了什么呢？

我们前面说过，**JS 引擎是独立于渲染引擎存在的**。我们的 JS 代码在文档的何处插入，就在何处执行。当 HTML 解析器遇到一个 script 标签时，它会暂停渲染过程，将控制权交给 JS 引擎。JS 引擎对内联的 JS 代码会直接执行，对外部 JS 文件还要先获取到脚本、再进行执行。等 JS 引擎运行完毕，浏览器又会把控制权还给渲染引擎，继续 CSSOM 和 DOM 的构建。 因此**与其说是 JS 把 CSS 和 HTML 阻塞了，不如说是 JS 引擎抢走了渲染引擎的控制权。**

现在理解了阻塞的表现与原理，我们开始思考一个问题。浏览器之所以让 JS 阻塞其它的活动，是因为它不知道 JS 会做什么改变，担心如果不阻止后续的操作，会造成混乱。但是我们是写 JS 的人，我们知道 JS 会做什么改变。假如我们可以确认一个 JS 文件的执行时机并不一定非要是此时此刻，我们就可以通过对它使用 defer 和 async 来避免不必要的阻塞，这里我们就引出了外部 JS 的三种加载方式。

**JS的三种加载方式**

* 正常模式：

  ```js
  <script src="index.js"></script>
  ```

这种情况下 JS 会阻塞浏览器，浏览器必须等待 index.js 加载和执行完毕才能去做其它事情。

* async 模式：

  ```js
  <script async src="index.js"></script>
  ```

async 模式下，JS 不会阻塞浏览器做任何其它的事情。它的加载是异步的，当它加载结束，JS 脚本会**立即执行**。

* defer 模式：

  ```js
  <script defer src="index.js"></script>
  ```

defer 模式下，JS 的加载是异步的，执行是**被推迟的**。等整个文档解析完成、DOMContentLoaded 事件即将被触发时，被标记了 defer 的 JS 文件才会开始依次执行。

从应用的角度来说，一般当我们的脚本与 DOM 元素和其它脚本之间的依赖关系不强时，我们会选用 async；当脚本依赖于 DOM 元素和其它脚本的执行结果时，我们会选用 defer。

通过审时度势地向 script 标签添加 async/defer，我们就可以告诉浏览器在等待脚本可用期间不阻止其它的工作，这样可以显著提升性能。

##### DOM优化原理与基本实践

> 把 DOM 和 JavaScript 各自想象成一个岛屿，它们之间用收费桥梁连接。——《高性能 JavaScript》
>
> JS 引擎和渲染引擎（浏览器内核）是独立实现的。当用 JS 去操作 DOM 时，本质上是 JS 引擎和渲染引擎之间进行了“跨界交流”。
>
> 岛上是渲染树~~

###### DOM 优化思路

让JS给DOM分压

```html
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>DOM操作测试</title>
</head>
<body>
  <div id="container"></div>
</body>
</html>
```

此时有一个假需求——想往 container 元素里写 10000 句一样的话。如果这么做：

```js
for(var count=0;count<10000;count++){ 
  document.getElementById('container').innerHTML+='<span>我是一个小测试</span>'
} 
```

这段代码有两个明显的可优化点。

第一点，**过路费交太多了**,每一次循环都调用 DOM 接口重新获取了一次 container 元素，相当于每次循环都交了一次过路费。前后交了 10000 次过路费，但其中 9999 次过路费都可以用**缓存变量**的方式节省下来：

```js
// 只获取一次container
let container = document.getElementById('container')
for(let count=0;count<10000;count++){ 
  container.innerHTML += '<span>我是一个小测试</span>'
}
```

第二点，**不必要的 DOM 更改太多了**。 10000 次循环里，修改了 10000 次 DOM 树。我们前面说过，对 DOM 的修改会引发渲染树的改变、进而去走一个（可能的）回流或重绘的过程，而这个过程的开销是很“贵”的。这么贵的操作，竟然重复执行了 N 多次！其实可以通过**就事论事**的方式节省下来不必要的渲染：

```
let container = document.getElementById('container')
let content = ''
for(let count=0;count<10000;count++){ 
  // 先对内容进行操作
  content += '<span>我是一个小测试</span>'
} 
// 内容处理好了,最后再触发DOM的更改
container.innerHTML = content

```

所谓“就事论事”，即JS 层面的事情，JS 自己去处理，处理好了，再来找 DOM 打报告。

事实上，考虑JS 的运行速度，比 DOM 快得多这个特性。

减少 DOM 操作的核心思路，就是**让 JS 去给 DOM 分压**。

这个思路，在 [DOM Fragment](https://developer.mozilla.org/zh-CN/docs/Web/API/DocumentFragment) 中体现得淋漓尽致。

> DocumentFragment 接口表示一个没有父级文件的最小文档对象。它被当做一个轻量版的 Document 使用，用于存储已排好版的或尚未打理好格式的XML片段。因为 DocumentFragment 不是真实 DOM 树的一部分，它的变化不会引起 DOM 树的重新渲染的操作（reflow），且不会导致性能等问题。



在上面的例子里，字符串变量 content 就扮演着一个 DOM Fragment 的角色。其实无论字符串变量也好，DOM Fragment 也罢，它们本质上都作为**脱离了真实 DOM 树的容器**出现，用于**缓存批量化的 DOM 操作**。

前面直接用 innerHTML 去拼接目标内容，这样做固然有用，却不够优雅。相比之下，DOM Fragment 可以用更加结构化的方式去达成同样的目的，从而在维持性能的同时，保住代码的可拓展和可维护性。现在用 DOM Fragment 来改写上面的例子：

```js
let container = document.getElementById('container')
// 创建一个DOM Fragment对象作为容器
let content = document.createDocumentFragment()
for(let count=0;count<10000;count++){
  // span此时可以通过DOM API去创建
  let oSpan = document.createElement("span")
  oSpan.innerHTML = '我是一个小测试'
  // 像操作真实DOM一样操作DOM Fragment对象
  content.appendChild(oSpan)
}
// 内容处理好了,最后再触发真实DOM的更改
container.appendChild(content)
```

运行这段代码，可以得到与前面两种写法相同的运行结果。  
可以看出，DOM Fragment 对象允许**像操作真实 DOM 一样去调用各种各样的 DOM API**，代码质量因此得到了保证。并且它的身份也非常纯粹：当试图将其 append 进真实 DOM 时，它会在乖乖交出自身缓存的所有后代节点后**全身而退**，完美地完成一个容器的使命，而不会出现在真实的 DOM 结构中。

这种结构化、干净利落的特性，使得 DOM Fragment 作为经典的性能优化手段大受欢迎，这一点在 jQuery、Vue 等优秀前端框架的源码中均有体现。

###### 异步更新策略

搞懂 Event Loop，理解 Vue 对 DOM 操作优化的第一步。

事件循环中的异步队列有两种：macro宏任务与micro微任务队列

- 常见 macro-task： setTimeout、setInterval、 setImmediate、script（整体代码）、 I/O 操作、UI 渲染等。  
- 常见micro-task: process.nextTick、Promise、MutationObserver 等。



一个**完整的 Event Loop 过程**，可以概括为以下阶段：

*   初始状态：调用栈空。micro 队列空，macro 队列里有且只有一个 script 脚本（整体代码）。

*   全局上下文（script 标签）被推入调用栈，同步代码执行。在执行的过程中，通过对一些接口的调用，可以产生新的 macro-task 与 micro-task，它们会分别被推入各自的任务队列里。同步代码执行完了，script 脚本会被移出 macro 队列，**这个过程本质上是队列的 macro-task 的执行和出队的过程**。

*   上一步我们出队的是一个 macro-task，这一步我们处理的是 micro-task。但需要注意的是：当 macro-task 出队时，任务是**一个一个**执行的；而 micro-task 出队时，任务是**一队一队**执行的（如下图所示）。因此，我们处理 micro 队列这一步，会逐个执行队列中的任务并把它出队，直到队列被清空。

![](https://user-gold-cdn.xitu.io/2018/10/1/1662fc9d8bf609a6?w=480&h=410&f=png&s=8715)

*   **执行渲染操作，更新界面**（敲黑板划重点）。

*   检查是否存在 Web worker 任务，如果有，则对其进行处理 。

（上述过程循环往复，直到两个队列都清空）

我们总结一下，每一次循环都是一个这样的过程：

![](https://user-gold-cdn.xitu.io/2018/10/1/1662ff57ebe7a73f?w=857&h=243&f=png&s=28272)

**渲染的时机**

现在思考一个这样的问题：假如想要在异步任务里进行DOM更新，该把它包装成 micro 还是 macro 呢？

先假设它是一个 macro 任务，比如在 script 脚本中用 setTimeout 来处理它：

```js
// task是一个用于修改DOM的回调
setTimeout(task, 0)
```

现在 task 被推入的 macro 队列。但因为 script 脚本本身是一个 macro 任务，所以本次执行完 script 脚本之后，下一个步骤就要去处理 micro 队列了，再往下就去执行了一次 render，对不对？

但本次render我的目标task其实并没有执行，想要修改的DOM也没有修改，因此这一次的render其实是一次无效的render。

macro 不 ok，转向 micro 试试看。用 Promise 来把 task 包装成是一个 micro 任务：

```js
Promise.resolve().then(task)
```

那么结束了对 script 脚本的执行，是不是紧接着就去处理 micro-task 队列了？micro-task 处理完，DOM 修改好了，紧接着就可以走 render 流程了——不需要再消耗多余的一次渲染，不需要再等待一轮事件循环，直接为用户呈现最即时的更新结果。

因此，更新 DOM 的时间点，**应该尽可能靠近渲染**的时机。**当需要在异步任务中实现 DOM 修改时，把它包装成 micro 任务是相对明智的选择**。



**生产实践：异步更新策略——以 Vue 为例**

什么是异步更新？

当使用 Vue 或 React 提供的接口去更新数据时，这个更新并不会立即生效，而是会被推入到一个队列里。待到适当的时机，队列中的更新任务会被**批量触发**。这就是异步更新。

异步更新可以帮助避免过度渲染，是“让 JS 为 DOM 分压”的典范之一。

**异步更新的优越性**

异步更新的特性在于它**只看结果**，因此渲染引擎**不需要为过程买单**。

最典型的例子，比如有时我们会遇到这样的情况：

```js
// 任务一
this.content = '第一次测试'
// 任务二
this.content = '第二次测试'
// 任务三
this.content = '第三次测试'
```

我们在三个更新任务中对同一个状态修改了三次，如果我们采取传统的同步更新策略，那么就要操作三次 DOM。但本质上需要呈现给用户的目标内容其实只是第三次的结果，也就是说只有第三次的操作是有意义的——白白浪费了两次计算。

但如果把这三个任务塞进异步更新队列里，它们会先在 JS 的层面上被**批量执行完毕**。当流程走到渲染这一步时，它仅仅需要针对有意义的计算结果操作一次 DOM——这就是异步更新的妙处。

**Vue状态更新手法：nextTick**

Vue 每次想要更新一个状态的时候，会先把它这个更新操作给包装成一个异步操作派发出去。这件事情，在源码中是由一个叫做 nextTick 的函数来完成的：

```js
export function nextTick (cb?: Function, ctx?: Object) {
  let _resolve
  callbacks.push(() => {
    if (cb) {
      try {
        cb.call(ctx)
      } catch (e) {
        handleError(e, ctx, 'nextTick')
      }
    } else if (_resolve) {
      _resolve(ctx)
    }
  })
  // 检查上一个异步任务队列（即名为callbacks的任务数组）是否派发和执行完毕了。pending此处相当于一个锁
  if (!pending) {
    // 若上一个异步任务队列已经执行完毕，则将pending设定为true（把锁锁上）
    pending = true
    // 是否要求一定要派发为macro任务
    if (useMacroTask) {
      macroTimerFunc()
    } else {
      // 如果不说明一定要macro 你们就全都是micro
      microTimerFunc()
    }
  }
  // $flow-disable-line
  if (!cb && typeof Promise !== 'undefined') {
    return new Promise(resolve => {
      _resolve = resolve
    })
  }
}
```

可以看到，Vue 的异步任务默认情况下都是用 Promise 来包装的，也就是是说它们都是 micro-task。这一点和“前置知识”中的渲染时机的分析不谋而合。

为了带大家熟悉一下常见的 macro 和 micro 派发方式、加深对 Event Loop 的理解，继续细化解析一下 macroTimeFunc() 和 microTimeFunc() 两个方法。

macroTimeFunc() 是这么实现的：

```js
// macro首选setImmediate 这个兼容性最差
if (typeof setImmediate !== 'undefined' && isNative(setImmediate)) {
  macroTimerFunc = () => {
    setImmediate(flushCallbacks)
  }
} else if (typeof MessageChannel !== 'undefined' && (
    isNative(MessageChannel) ||
    // PhantomJS
    MessageChannel.toString() === '[object MessageChannelConstructor]'
  )) {
  const channel = new MessageChannel()
  const port = channel.port2
  channel.port1.onmessage = flushCallbacks
  macroTimerFunc = () => {
    port.postMessage(1)
  }
} else {
  // 兼容性最好的派发方式是setTimeout
  macroTimerFunc = () => {
    setTimeout(flushCallbacks, 0)
  }
}
```

microTimeFunc() 是这么实现的：

```js
// 简单粗暴 不是ios全都给我去Promise 如果不兼容promise 那么你只能将就一下变成macro了
if (typeof Promise !== 'undefined' && isNative(Promise)) {
  const p = Promise.resolve()
  microTimerFunc = () => {
    p.then(flushCallbacks)
    // in problematic UIWebViews, Promise.then doesn't completely break, but
    // it can get stuck in a weird state where callbacks are pushed into the
    // microtask queue but the queue isn't being flushed, until the browser
    // needs to do some other work, e.g. handle a timer. Therefore we can
    // "force" the microtask queue to be flushed by adding an empty timer.
    if (isIOS) setTimeout(noop)
  }
} else {
  // 如果无法派发micro，就退而求其次派发为macro
  microTimerFunc = macroTimerFunc
}
```

可以注意到，无论是派发 macro 任务还是派发 micro 任务，派发的任务对象都是一个叫做 flushCallbacks 的东西，这个东西做了什么呢？

flushCallbacks 源码如下：

```js
function flushCallbacks () {
  pending = false
  // callbacks在nextick中出现过 它是任务数组（队列）
  const copies = callbacks.slice(0)
  callbacks.length = 0
  // 将callbacks中的任务逐个取出执行
  for (let i = 0; i < copies.length; i++) {
    copies[i]()
  }
}
```

Vue 中每产生一个状态更新任务，它就会被塞进一个叫 callbacks 的数组（此处是任务队列的实现形式）中。这个任务队列在被丢进 micro 或 macro 队列之前，会先去检查当前是否有异步更新任务正在执行（即检查 pending 锁）。如果确认 pending 锁是开着的（false），就把它设置为锁上（true），然后对当前 callbacks 数组的任务进行派发（丢进 micro 或 macro 队列）和执行。设置 pending 锁的意义在于保证状态更新任务的有序进行，避免发生混乱。





###### 回流与重绘

*   回流：当对 DOM 的修改引发了 DOM 几何尺寸的变化（比如修改元素的宽、高或隐藏元素等）时，浏览器需要重新计算元素的几何属性（其他元素的几何属性和位置也会因此受到影响），然后再将计算的结果绘制出来。这个过程就是回流（也叫重排）。

*   重绘：当对 DOM 的修改导致了样式的变化、却并未影响其几何属性（比如修改了颜色或背景色）时，浏览器不需重新计算元素的几何属性、直接为该元素绘制新的样式（跳过了上图所示的回流环节）。这个过程叫做重绘。

**重绘不一定导致回流，回流一定会导致重绘**。硬要比较的话，回流比重绘做的事情更多，带来的开销也更大。

但这两个说到底都是吃性能的，所以都不是什么善茬。我们在开发中，要从代码层面出发，尽可能把回流和重绘的次数最小化。

**回流导火索**

*   最“贵”的操作：改变 DOM 元素的几何属性

这个改变几乎可以说是“牵一发动全身”——当一个DOM元素的几何属性发生变化时，所有和它相关的节点（比如父子节点、兄弟节点等）的几何属性都需要进行重新计算，它会带来巨大的计算量。

常见的几何属性有 width、height、padding、margin、left、top、border 等等。

*   “价格适中”的操作：改变 DOM 树的结构

这里主要指的是节点的增减、移动等操作。浏览器引擎布局的过程，顺序上可以类比于树的前序遍历——它是一个从上到下、从左到右的过程。通常在这个过程中，当前元素不会再影响其前面已经遍历过的元素。

*   最容易被忽略的操作：获取一些特定属性的值

当用到像这样的属性：offsetTop、offsetLeft、 offsetWidth、offsetHeight、scrollTop、scrollLeft、scrollWidth、scrollHeight、clientTop、clientLeft、clientWidth、clientHeight 时，就要注意了！

“像这样”的属性，到底是像什么样？——这些值有一个共性，就是需要通过**即时计算**得到。因此浏览器为了获取这些值，也会进行回流。

除此之外，当调用了 getComputedStyle 方法，或者 IE 里的 currentStyle 时，也会触发回流。原理是一样的，都为求一个“即时性”和“准确性”。

**如何规避回流与重绘**

1、将“导火索”缓存起来，避免频繁改动

有时想要通过多次计算得到一个元素的布局位置，可能会这样做：

```html
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Document</title>
  <style>
    #el {
      width: 100px;
      height: 100px;
      background-color: yellow;
      position: absolute;
    }
  </style>
</head>
<body>
  <div id="el"></div>
  <script>
  // 获取el元素
  const el = document.getElementById('el')
  // 这里循环判定比较简单，实际中或许会拓展出比较复杂的判定需求
  for(let i=0;i<10;i++) {
      el.style.top  = el.offsetTop  + 10 + "px";
      el.style.left = el.offsetLeft + 10 + "px";
  }
  </script>
</body>
</html>
```

这样做，每次循环都需要获取多次“敏感属性”，是比较糟糕的。可以将其以 JS 变量的形式缓存起来，待计算完毕再提交给浏览器发出重计算请求：

```js
// 缓存offsetLeft与offsetTop的值
const el = document.getElementById('el') 
let offLeft = el.offsetLeft, offTop = el.offsetTop
// 在JS层面进行计算
for(let i=0;i<10;i++) {
  offLeft += 10
  offTop  += 10
}
// 一次性将计算结果应用到DOM上
el.style.left = offLeft + "px"
el.style.top = offTop  + "px"
```

2、避免逐条改变样式，使用类名去合并样式

比如可以把这段单纯的代码：

```js
const container = document.getElementById('container')
container.style.width = '100px'
container.style.height = '200px'
container.style.border = '10px solid red'
container.style.color = 'red'
```

优化成一个有 class 加持的样子：

```js
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Document</title>
  <style>
    .basic_style {
      width: 100px;
      height: 200px;
      border: 10px solid red;
      color: red;
    }
  </style>
</head>
<body>
  <div id="container"></div>
  <script>
  const container = document.getElementById('container')
  container.classList.add('basic_style')
  </script>
</body>
</html>

```

前者每次单独操作，都去触发一次渲染树更改，从而导致相应的回流与重绘过程。

合并之后，等于我们将所有的更改一次性发出，用一个 style 请求解决掉了。

3、将 DOM “离线”

上文所说的回流和重绘，都是在“该元素位于页面上”的前提下会发生的。一旦给元素设置 display: none，将其从页面上“拿掉”，那么后续操作，将无法触发回流与重绘——这个将元素“拿掉”的操作，就叫做 DOM 离线化。

仍以上文的代码片段为例：

```js
const container = document.getElementById('container')
container.style.width = '100px'
container.style.height = '200px'
container.style.border = '10px solid red'
container.style.color = 'red'
...（省略了许多类似的后续操作）
```

离线化后就是这样：

```js
let container = document.getElementById('container')
container.style.display = 'none'
container.style.width = '100px'
container.style.height = '200px'
container.style.border = '10px solid red'
container.style.color = 'red'
...（省略了许多类似的后续操作）
container.style.display = 'block'
```

有的同学会问，拿掉一个元素再把它放回去，这不也会触发一次昂贵的回流吗？这话不假，但我们把它拿下来了，后续不管我操作这个元素多少次，每一步的操作成本都会非常低。当我们只需要进行很少的 DOM 操作时，DOM 离线化的优越性确实不太明显。一旦操作频繁起来，这“拿掉”和“放回”的开销都将会是非常值得的。

###### Flush 队列：浏览器并没有那么简单

以现在的知识基础，理解上面的优化操作并不难。那么现在我问大家一个问题：

```js
let container = document.getElementById('container')
container.style.width = '100px'
container.style.height = '200px'
container.style.border = '10px solid red'
container.style.color = 'red'
```

这段代码里，浏览器进行了多少次的回流或重绘呢？

“width、height、border是几何属性，各触发一次回流；color只造成外观的变化，会触发一次重绘。”——如果你立刻这么想了，说明你是个能力不错的同学，认真阅读了前面的内容。那么我们现在立刻跑一跑这段代码，看看浏览器怎么说：

![](https://user-gold-cdn.xitu.io/2018/10/4/1663f57519a785ab?w=1284&h=96&f=png&s=18506)

这里为大家截取有“Layout”和“Paint”出镜的片段（这个图是通过 Chrome 的 Performance 面板得到的，后面会教大家用这个东西）。我们看到浏览器只进行了一次回流和一次重绘——和我们想的不一样啊，为啥呢？

因为现代浏览器是很聪明的。浏览器自己也清楚，如果每次 DOM 操作都即时地反馈一次回流或重绘，那么性能上来说是扛不住的。于是它自己缓存了一个 flush 队列，把触发的回流与重绘任务都塞进去，待到队列里的任务多起来、或者达到了一定的时间间隔，或者“不得已”的时候，再将这些任务一口气出队。因此看到，上面就算进行了 4 次 DOM 更改，也只触发了一次 Layout 和一次 Paint。

这里尤其小心这个“不得已”的时候。前面介绍回流的“导火索”的时候，提到过有一类属性很特别，它们有很强的“即时性”。当我们访问这些属性时，浏览器会为了获得此时此刻的、最准确的属性值，而提前将 flush 队列的任务出队——这就是所谓的“不得已”时刻。具体是哪些属性值，已经在“最容易被忽略的操作”这个小模块介绍过了，此处不再赘述。

###### 小结

整个一节读下来，可能会有同学感到疑惑：既然浏览器已经为我们做了批处理优化，为什么我们还要自己操心这么多事情呢？今天避免这个明天避免那个，多麻烦！

问题在于，**并不是所有的浏览器都是聪明的**。刚刚的性能图表，是 Chrome 的开发者工具呈现给我们的。Chrome 里行得通的东西，到了别处（比如 IE）就不一定行得通了。而开发者并不知道用户会使用什么样的浏览器。如果不手动做优化，那么一个页面在不同的环境下就会呈现不同的性能效果，这对开发、对用户都是不利的。因此，养成良好的编码习惯、从根源上解决问题，仍然是最周全的方法。

